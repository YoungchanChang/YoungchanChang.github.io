---
layout: post
title: 강의정리 04 - 3Blue1Brown 01- introduction
category: ML_Summary
tags: [ML]
comments: ML
---

# 신경망 구조가 만들어진 토대(Structure)

- 뇌는 어떻게 숫자를 인식하는 것일까?

- 픽셀의 모양이 달라도 **다 같은 3이라고 인식**한다. 눈 안에 있는 시지각 세포들이 **빛 신호를 받아들이는 패턴은, 서로 다른 반응**을 한다. 시각피질은 이런 차이에도 불구하고, 서로 다른 모양의 픽셀의 3을 다 같은 3이라고 인식한다. 동시에 6이나 8을 구분한다.

<center>
<figure>
<img src="https://imgur.com/X0rWB4f.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

### 컴퓨터가 숫자를 인식하기까지

- What is Neural Network

### 컴퓨터에서 Neuron(신경세포)란?

- Thing that holds a number. **숫자를 담고있는 공간**으로 해석할 수 있다.

- 숫자를 담고 있는 공간은 이전 값들을 받아서 활성화 되는지 안 되는지를 결정한다. 따라서 neuron은 **입력한 값을 활성화시키는 함수**라고 할 수 있다.

- 28x28(784)개의 픽셀들을 입력값을 취급할 때, 각 뉴런들은 픽셀의 밝기를 나타낸다. 신경망에서는 이러한 숫자들을 **입력값(Activation)**이라고 부른다.

- 큰 입력값이 주어질수록 각각의 신경망이 더 큰 정도로 활성화 된다.

<center>
<figure>
<img src="https://imgur.com/TZmckRK.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

### 컴퓨터에서 Network란?

- How ar they connected(network). 각 뉴런들이 어떻게 연결되어있는가를 나타낸다.

- 정보처리에서는 **어떻게 다른층의 활성화**를 불러일으킬가가 중요하다.

- 몇몇의 **뉴런의 활성화가 다른 뉴런의 활성화를 수반**한다.

- **출력층에서 가장 빛나는 뉴런**이 이 신경망에서 선택된 출력값이다.

<center>
<figure>
<img src="https://imgur.com/twcka0D.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

### 컴퓨터에서 Neural Network가 지적으로 동작할까?

- 사람은 숫자를 인식할 때 **각 부분을 합친다**. 9는 0과 1로 인식한다.

- 두번째 층의 각 뉴런들이 이러한 부분들에 대응해야한다.

<center>
<figure>
<img src="https://imgur.com/crXtxJM.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 셋째 층에서 마지막층으로 갈 때 **어떤 결합**으로 볼 것인가만 보면 된다.

<center>
<figure>
<img src="https://imgur.com/hodBw4w.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 어떻게 각 부분들을 인지할 것이고, 어떤 위치에 있어야 하는가. 한 층의 활성화는 다음 층의 활성화로 어떻게 진행되는가?

- 둘째층의 뉴런들은 셋째층의 모서리로 표현할 수 있다.

<center>
<figure>
<img src="https://imgur.com/GsqJsDK.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 최종적인 그림

<center>
<figure>
<img src="https://imgur.com/1bK1Fjr.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

# 왜 layer이 지적일까? 가운데 층들은  무엇을 할까?


- 9는 0과 1로 인식하게 된다. 

- 0는 여러개로 쪼갤 수 있다.

- 1, 4, 7도 쪼갤 수 있다. 2번째 층은 수 많은 작은 조각들에 대응할 수 있다.

- 일정한 방식의 테두리는 다른 이미지 처리 작업에도 유용하다.

- 음성분석은 특정한 소리들을 합쳐 음절을 만들고, 단어를 합쳐 문장과 추상적인 생각들을 구현한다.

- 한층의 호라성화가 어떻게 다른 츠의 활성화를 이끔?

- 픽셀을 테두리로 결합시키거나 테두리를 패턴으로 결합시키거나, 패턴을 숫자로 결합하는 매커니즘을 만든다.

# 숫자를 인식하기 까지

- 결과물은 여러 **부분의 조합**이다.

<center>
<figure>
<img src="https://imgur.com/mxI9lvM.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 두번째 층은 **모서리를 인식**하고, 세번째 층은 **패턴을 인식**하게 한다.

<center>
<figure>
<img src="https://imgur.com/No5DcY7.png" alt="views">
<figcaption></figcaption>
</figure>
</center>


# 수식으로 표현하기 H(x) = W * x + b

- 입력값을 모서리로 인식하게 하기 위해서는 어떤 변수들을 입력값에 주어야 할까?

<center>
<figure>
<img src="https://imgur.com/mcym4lc.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

# Weight의 의미

- 첫 층의 뉴런과 둘째층의 뉴런을 있는 **신경에 가중치를 부여**하면 된다.

<center>
<figure>
<img src="https://imgur.com/FJsluiF.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 입력값에 가중치를 곱하면 활성화 값이 나오게 된다. 그 **영역의 픽셀에만 가중치를 주어** 더한 것과 같은 상황이 된다.

<center>
<figure>
<img src="https://imgur.com/BmotueZ.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 이 값을 활성화시키기 위해서는 0과 1사이의 숫자로 만들어주는 sigmoid함수에 넣는다.

# Bias의 의미

- Bias의 역할 : 가중치가 10보다 클 때 활성화되기를 원할 수도 있다. Bias for inactivity!!! **활성화되지 않기 위한 조건**을 의미한다.

- bias는 가중치의 합이 얼마나 높아야 활성화하는지 하는지를 알려준다.

- 가중치는 뉴런의 **픽셀 패턴**을 알려주고, bias는 뉴런이 활성화되려면 **가중치의 합이 얼마나 더 높아져야 하는지**를 알려준다.

- sigmoid : 해당 input을 다음 Layer에 **활성화시켜줄지 안 할지 정한다**. 

### 전체적인 그림

- 첫째 층의 **각각의 뉴런들은 이전 모든 뉴런들과 연결**이 된다.

<center>
<figure>
<img src="https://imgur.com/TrvzVuY.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 이렇게 만들어진 모든 뉴런들과 연결은 서로 각각 다르게 행동한다.

<center>
<figure>
<img src="https://imgur.com/l1vRSxO.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- Learning이란 wieght과 bias를 찾기 위한 행동이다.

- 사람이 만약 프로그래밍을 한다면 **의도적으로 두번재 층은 모서리를 인식하고, 세번째 층은 패턴을 인식**하게 한다.

- 한 층은 이전 층의 값을 선택한다!

### 전체 수식으로 표현하기

- 행렬의 곱으로 표현할 수 있따

- input값을 열 vector로 나타낸다.

- 행렬의 각 열은 **한 층과 다음 층의 특정 뉴런의 연결**을 나타낸다.

- 가중치들에 따라 활성화정도(bias)를 더한 것이 **열벡터의 각 원소에 대응**하게 된다.

<center>
<figure>
<img src="https://imgur.com/KgfbYXb.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 간결한 식으로 표현하기

<center>
<figure>
<img src="https://imgur.com/MIHU7el.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

