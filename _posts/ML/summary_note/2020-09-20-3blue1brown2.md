---
layout: post
title: 강의정리 04 - 3Blue1Brown 02- Learning
category: ML_Summary
tags: [ML]
comments: ML
---

# 신경망 구조의 학습(Learning)

- Gradient descent (신경망 학습과 다른 기계학습의 작동을 알 수 있다)

- Network 평가(신경망이 어떻게 작동하는지, 숨겨진 층들의 뉴런의 의미)

# 기계학습이란

- 기계학습은 가중치 함수의 최솟값을 찾는 일로 요약될 수 있다.

<center>
<figure>
<img src="https://imgur.com/tw8rdUs.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 각 뉴런은 **이전 층의 모든 뉴런과 연결**되어 있고, 가중치는 **연결의 세기**와 같은 것이다. bias는 **뉴런이 활동적인지 비활동적인지**를 나타내는 지표이다.

# Cost Function

- 기계는 신경구조망에 의해서 결과물을 내놓게 된다.

<center>
<figure>
<img src="https://imgur.com/eNA7SZU.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 그러면 기계에게 출력된 결과물이 맞았는지, 틀렸는지에 대해서 판단해줘야한다.

<center>
<figure>
<img src="https://imgur.com/wcfwp2t.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 딥러닝에서는 weight값이 매우 많으므로, Weight 하나에 대한 Cost Function()을 가정해보자.

<center>
<figure>
<img src="https://imgur.com/JdySSlL.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- weight에 대한 Cost Function()은 2차함수로 미분을 통해 값을 구할 수 있다.

<center>
<figure>
<img src="https://imgur.com/vIsjqLc.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- weigt가 여러개일 때 Cost Function()은 입체적인 모양이 되며 언덕에서 내려가는 공처럼 최저점을 찾아갈 수 있다.

<center>
<figure>
<img src="https://imgur.com/wqJLpvN.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 미분점을 구한 뒤 해당 값을 빼는 과정을 반복하면 된다.

<center>
<figure>
<img src="https://imgur.com/Ho0kr2c.png" alt="views">
<figcaption></figcaption>
</figure>
</center>


# 식으로 보기

- Weight의 각각의 값에 대해서 벡터로 표현했다고 하자

<center>
<figure>
<img src="https://imgur.com/0LkVuXA.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 각 Weight에 대해서 어떤 방향이 cost를 빠르게 감소하는지 미분을 통해 구할 수 있다.

<center>
<figure>
<img src="https://imgur.com/wDmV8kv.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 경사 기울기는 입력 벡터의 요소가 커져야 할지 작아져야 할지를 알려준다.

<center>
<figure>
<img src="https://imgur.com/ardsiTV.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- **결과와 직접적으로 연결된** weight는 훈련데이터에 더 민감하게 반응한다.

<center>
<figure>
<img src="https://imgur.com/0qi4kPD.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- 결과와 직접적으로 연결된 weight을 조정하면 효과가 더 좋게 된다.

<center>
<figure>
<img src="https://imgur.com/ywNMdCw.png" alt="views">
<figcaption></figcaption>
</figure>
</center>
