---
layout: post
title: 모두를 위한 딥러닝 13 - Softmax Regression
category: ML
tags: [ML]
comments: ML
---

# 예측

- 예측을 한다는 것은 X를 보고 Y의 값이 무엇일지 예측하는 것이다. 예측을 하기 위해서는 변수들의 상관관계가 있어야 한다.

- Linear Regerssion은 X의 값이 주어졌을 때 Y의 값을 추론하는 것이다.

- Logistic Regression은 X의 값이 주어졌을 때 Y의 값이 생기고 여기서 sigmoid함수를 써서 0~1사이 값으로 추려서 0이면 거짓, 1이면 참으로 만든다.

- Softmax Regression은 X의 값이 주어졌을 때 Y의 값을 추론한 다음에, 각각에 sigmoid함수를 쓰지 않고 합들에 대해서 softmax로 처리한다. **시그모이드가 아닌 softmax를 쓰면 확률**이 된다. 값이 여러개임으로, w의 값도 여러개가 된다. 채점을 할 때는 원핫인코딩을 쓴다. 예측 값은 확률이 되게 된다.

- SOFTMAX 또는 확률이라고 이야기한다.

- 기존 식과 달라진 점 : 1. 결과값을 원핫인코딩한다. 원핫인코딩은 cost/loss에 쓰인다. 2.가설에 softmax함수를 쓴다.

- Weight를 쓸 때 주의할 점 [행 x 열] x [열 x 결과값]이 된다. 열의 개수를 인자로 줘야한다는 것을 잊지 말자.

- 가설(hypothesis) => 결과() => 재조정

- X의 값은 Y일 것이다. X의 값은 Y의 점수가 나왔고 이것은 참일 것이다. X의 값들을 모아보니 Y의 클래스들이 나왔고 이것은 참일 것이다.