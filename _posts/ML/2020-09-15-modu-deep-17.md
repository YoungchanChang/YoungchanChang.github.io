---
layout: post
title: 모두를 위한 딥러닝 17 - Backpropagation과 딥의 출현
category: ML
tags: [ML]
comments: ML
---

# np 잘 다루기

<center>
<figure>
<img src="https://imgur.com/52jP6nu.png" alt="views">
<figcaption></figcaption>
</figure>
</center>


### SimpleArray

```python
t = np.array([0., 1., 2., 3., 4., 5., 6.])
pp.pprint(t)
print(t.ndim) # rank
print(t.shape) # shape
print(t[0], t[1], t[-1])
print(t[2:5], t[4:-1])
print(t[:2], t[3:])
```

- 몇 차원 array인가 - rank

- array에 몇개 element가 있냐 -shape

- element indexing하면 된다.

- [-1]은 특별한 의미로 제일 마지막을 의미한다.

- 일부만 뽑고싶다 == slice

- [4:-1]은 4부터 마지막 앞까지를 의미한다. **바로 앞까지를 의미**한다.

### 2D Array

```python
t = np.array([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.], [10., 11., 12.]])
pp.pprint(t)
print(t.ndim) # rank
print(t.shape) # shape
```

- shape : 몇 개가 들어있냐, 행, 렬로 보여진다.
    - Matrix곱할 때 shape이 맞아야 하기 때문에 자주 쓰인다.

- rank는 차원이다.

- axis : 축이 몇개이냐. Axis는 제일 안쪽이 -1, 바깥이 0이다.

### Matmul vs multiply

- matrix곱할 때는 **shape**을 생각해야한다!!!

- multiply의 곱은 matmul과 상당히 다른 값을 갖게 된다!!!

- matrix곱인지 일반적인 multiply인지 확인해야한다!!!

### Broadcasting

- 2개의 shape은 같은 shape이기 때문에 각각 합해진다.

```python
matrix1 = tf.constant([[3., 3.]])
matrix2 = tf.constant([[2.],[2.]])
(matrix1+matrix2).eval()
```

- shape이 다르더라도 연산을 가능하게 해준다. 격을 맞춰주는 것이 Broadcasting이다.

- 잘 모르고 사용하면 잘못된 결과를 초래한다.

- 가급적 앞 뒤의 shape을 고려해서 연산하는게 좋다.


### Reduce mean

- 평균을 줄여서 구한다. 행렬의 여러 갚들을 출력하고 싶다. 

- 반드시 floating point로 구해야 한다. rank가 2개이면 축이 2개가 된다.

- axis가 0이면 열의 평균을 구한다.

```
tf.reduce_mean(x, axis=0).eval()
```

- axis가 1이면 행의 평균을 구한다.

```
tf.reduce_mean(x, axis=1).eval()
```

- axis가 -1이면 가장 안쪽에 있는 것을 구해라

```
tf.reduce_mean(x, axis=-1).eval()
array([ 1.5,  3.5], dtype=float32)
```

### Reduce_sum

- 행의 축이 1 열의 축이 0이 된다.

- 보통 제일 **안쪽에 있는 축**을 합을 한 다음에 평균을 낸다. 안쪽에 있는 축이란 행이 기준

```
tf.reduce_mean(tf.reduce_sum(x, axis=-1)).eval()
```

### Argmax

- 축의 개념과 함께 사용된다. 2차원에서 axis=1은 행, axis=0는 열이다.

- 위치를 구한다. 가장 maximum값의 위치를 구한다.

```
x = [[0, 1, 2],
     [2, 1, 0]]
tf.argmax(x, axis=0).eval()
array([1, 0, 0])
tf.argmax(x, axis=-1).eval()
array([2, 0])
```

### Reshape

- 가장 많이 사용한다 별표 2개

- shape은 가장 안쪽부터 구한다. (2, 2, 3)

- reshape을 하면 랭크를 줄일 수 있고, 내가 원하는 형태의 shape을 줄 수 있다. 보통 가장 안 쪽에 있는 값은 잘 안건드린다. 전체적인 shape만 조금 변하게 된다. 

- rank를 더 늘릴 수도 있다.

```
t = np.array([[[0, 1, 2], 
               [3, 4, 5]],
              
              [[6, 7, 8], 
               [9, 10, 11]]])
t.shape
(2, 2, 3) - 3은 가장 안쪽

tf.reshape(t, shape=[-1, 3]).eval()
array([[ 0,  1,  2],
       [ 3,  4,  5],
       [ 6,  7,  8],
       [ 9, 10, 11]])

```

- squeeze와 expand : squeeze하면 값을 쫙 펴준다. expand는 dimention을 추가한다. tensor의 shape을 변경시키기 위한 방법이다.

### One hot
- 1, 2, 3, 4, 5를 자리를 보고 hot하게 변환시켜주는 방법이다. tensorflow의 one_hot이 존재한다.

- 원핫은 자동적으로 expand하게 된다. 원핫을 한 다음에 reshape를 하면 된다.

### Casting

- 주어진 tensor의 casting을 다 바꾼다.

- True False값을 개수를 더한 다음에 합할 때. 1과 0으로 변환시킨다.

### Stack

- 배열을 쌓는다.

- axis는 축의 개념. 축을 바꿈으로써 쌓을 수 있따.

### Ones and Zeros like

- 주어진 tensor가 있을 때,  똑같은 모양의 tensor로 만들 때 쓰인다. 0과 1을 만들어주세요

### Zip

- 복수개의 tensor를 갖고 있다. 각각을 한 번에 묶을 때 쓰인다.