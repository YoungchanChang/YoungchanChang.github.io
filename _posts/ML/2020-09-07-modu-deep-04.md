---
layout: post
title: 모두를 위한 딥러닝 04 - Linear Regression의 Hypothesis와 cost설명
category: ML
tags: [ML]
comments: ML
---

# Linear Regression

### 선형 회귀 모델이란

- 회귀 모델(regression) : 두 변수의 선형 **상관관계를 모델링** 하는 방식

- 예시 : 공부한 시간(x 값)과 **시험 성적(y 값)** 데이터를 통해 다음 시간에 따른 시험 성적 예측

### Linear Regression은 언제 쓰일까?

- Linear의 중요성? 많은 현상들이 Linear로 설명하는 경우가 많다.

- 예시 : 학생의 공부량과 성적, 훈련시간과 성적

### Linear Regression로 학습시키기

1] (Linear) 가설 세우기

- 데이터에 따라 어떤 Linear 선이 적합한지 찾는다. 선을 찾는 것이 곧 학습을 하는 것이다.

- 가설은 `H(x) = Wx + b` 1차 방정식이 나올 것이라고 세울 수 있다. 

2] 가설 판별하기

- 어떤 가설이 더 훌륭한가는 W와 b의 값으로 판별할 수 있다.

- 실제 데이터를 가설에 넣을 때 가설 점들과의 `거리`가 나온다. 거리가 멀면 안 좋은 모델이고, 가까우면 좋은 모델이다.

3] Cost Function(Loss Function)

- 가설과 실제 데이터가 얼마나 다른가를 판별해야한다.

- 실제 데이터 값과 가설의 차이의 값은 `(H(x) - y)²`로 값을 제곱을 한다.

- 제곱을 하게 되면  + - 상관 없이 양수로 표현할 수 있고 차이가 클 때 패널티를 많이 줄 수 있다.

- Cost Function은 `cost = (1/m)*∑(H(xi) - yi)²`이며, 데이터 개수(m)만큼 (예측한 값 - 실제값)²을 구하는 것이다.

- m은 학습 데이터의 갯수이다. 

4] Goal of Cost Function

- 손실 함수의 (W,b)의 값을 가장 작게 하는 것이 학습의 목적이다.

<center>
<figure>
<img src="https://imgur.com/vlGBqIL.png" alt="views">
<figcaption>하나의 노드</figcaption>
</figure>
</center>


<center>
<figure>
<img src="https://imgur.com/tVV0BFS.png" alt="views">
<figcaption>그래프를 빌드한다.</figcaption>
</figure>
</center>


# 참조
[데이터 플로우 그래프](https://yamerong.tistory.com/40)

[텐서플로우 참고자료](https://github.com/hunkim/DeepLearningZeroToAll/tree/master/tf2)