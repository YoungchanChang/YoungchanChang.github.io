---
layout: post
title: 200919_TIL
category: TIL
tags: [TIL]
comments: true
---

# 오늘 한 일

- 3blue1brown의 미적분 강의를 들었다. 모두의 딥러닝이 더 친절하다. 다만, 이미지로 시각적으로 보여준다는 점에서는 많은 것을 배웠다. 

- 숫자를 인식할 때 **각 부분을 합친다**. 두번째 층은 **모서리를 인식**하고, 세번째 층은 **패턴을 인식**하게 한다.


- 뉴런은 **이전 층의 모든 뉴런과 연결**되어 있고, 가중치는 **연결의 세기**와 같은 것이다. bias는 **뉴런이 활동적인지 비활동적인지**를 나타내는 지표라는 사실로 정의할 수 있었다.

- ChainRule로 weight값을 조절한다는 것은 input값에 영향을 받는다는 사실 **오차함수의 기울기가 0.1인 가중치보다 기울기가 3.2인 가중치가 32배 더 민감**하다고 해석할 수 있다.

- **직접 연관된 뉴런들**은 오차함수에 실제로 더 강한 영향을 미친다.

- **가장 활동적인 뉴런에서 연결**된다."Neurons that fire together wire together"

- 뉴런의 동작을 여러개를 이미지로 봤다는 점이 좋았다. 

# 내일 할 일

- 머신러닝 softmax regression까지 생각하기. 그림으로도 그려야하고 여러가지 생각을 해야한다.

- 도커를 연습해야된다. 그래야 테스트 서버에 올릴 때 더 자연스럽게 할 수 있다.

- 예시를 보면서 에러코드 처리를 어떻게 하는지 생각하고, 테스트서버에 localserver로 돌려본다. 그리고 문서화해야한다.

# 앞으로 해야 할 일

1. 도커 마무리짓기(9월 20일)
2. 정규식 공부 - 데이터가 들어와서 정규식으로 처리 해야 할 필요가 있다.
3. 엑셀 공부하기
4. ~~파이썬으로 웹 크롤링 시도하기 + flask 마무리짓기(9월 20일)~~
5. 모두를 위한 딥러닝 한 강의씩 듣기

- Linear Regression의 cost최소화의 Tensorflow까지 복습하기(9월 19일)

- ~~y = x1*w1 + x2*w2의 변수 2개인 경우 생각해보기~~

- logistic, softmax regression까지 공부하기

6. 리눅스 다루는 것 공부하기(아직 기본만 했다)


