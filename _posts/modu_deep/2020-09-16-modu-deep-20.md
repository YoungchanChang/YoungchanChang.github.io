---
layout: post
title: 모두를 위한 딥러닝 20 - XOR문제 해결하기
category: ML
tags: [ML]
comments: ML
---

# 기존 방식으로 XOR 문제 해결하기

- hypothesis세우기

<center>
<figure>
<img src="https://imgur.com/OGPjCku.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- Cost계산하기

<center>
<figure>
<img src="https://imgur.com/jpFy6Ev.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

- Graident 재조정하기

<center>
<figure>
<img src="https://imgur.com/81rq7A9.png" alt="views">
<figcaption></figcaption>
</figure>
</center>

```python
import numpy as np
import matplotlib.pyplot as plt
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()

# H L G
# Hypothesis
# H(x) = W*x + b
x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)
y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)

X = tf.placeholder(tf.float32, [None,2]) # 실제 데이터가 들어갈 자리
Y = tf.placeholder(tf.float32, [None,1]) # 결과 데이터가 들어갈 자리

W = tf.Variable(tf.random_normal([2,1]), name="weight")
b = tf.Variable(tf.random_normal([1,1]), name="bias")

hypothesis = tf.sigmoid(tf.matmul(X,W) + b)

# Cost구하기 - 실제 결과값과 예측값 비교
cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))
train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)

predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)
accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    
    for step in range(10001):
        _, cost_val, w_val = sess.run([train, cost, W], feed_dict={X:x_data, Y:y_data})
        if step % 100 == 0:
            print(step, cost_val, w_val)
    
    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X:x_data, Y:y_data})
    print("\nHypothesis: ", h, "\nCorrect: ", c, "\nAccuracy: ", a)
```

### deep하게 XOR문제 해결하기

```python
W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1') # Weight이 2개의 출력으로 나온다.
b1 = tf.Variable(tf.random_normal([2]), name='bias1')
layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)

W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2') # 이전에서 나온 2개의 출력을 받아서 1개의 출력으로 변환시켜준다.
b2 = tf.Variable(tf.random_normal([1]), name='bias2')
hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)
```

### 더 deep하게 XOR문제 해결하기

```python
W1 = tf.Variable(tf.random_normal([2, 10]), name='weight1')
b1 = tf.Variable(tf.random_normal([10]), name='bias1')
layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)

W2 = tf.Variable(tf.random_normal([10, 10]), name='weight2')
b2 = tf.Variable(tf.random_normal([10]), name='bias2')
layer2 = tf.sigmoid(tf.matmul(layer1, W2) + b2)

W3 = tf.Variable(tf.random_normal([10, 10]), name='weight3')
b3 = tf.Variable(tf.random_normal([10]), name='bias3')
layer3 = tf.sigmoid(tf.matmul(layer2, W3) + b3)

W4 = tf.Variable(tf.random_normal([10, 1]), name='weight4')
b4 = tf.Variable(tf.random_normal([1]), name='bias4')
hypothesis = tf.sigmoid(tf.matmul(layer3, W4) + b4)
```